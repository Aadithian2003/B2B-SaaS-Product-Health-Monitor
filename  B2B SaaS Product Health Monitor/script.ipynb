{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546c839d-d468-4f20-85f7-c724b1e2d555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loaded 50 real company names from Kaggle base ---\n",
      "Files 'users_activity.json' and 'account_meta.csv' are ready!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def load_base_companies(file_path):\n",
    "    \"\"\"\n",
    "    Attempts to load real company names from a Kaggle CSV.\n",
    "    If the file doesn't exist, it generates placeholders.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv('kaggle_companies.csv')\n",
    "        # Assuming Kaggle column is 'name' or 'Company Name'\n",
    "        # We take the first 50 unique names\n",
    "        # Change 'name' to whatever the column is called in your Kaggle CSV\n",
    "        names = df['Company Name'].dropna().unique()[:50].tolist()\n",
    "        print(f\"--- Loaded {len(names)} real company names from Kaggle base ---\")\n",
    "        return names\n",
    "    except FileNotFoundError:\n",
    "        print(\"--- Kaggle file not found. Falling back to synthetic names. ---\")\n",
    "        return [f\"Kaggle_Fallback_{i}\" for i in range(50)]\n",
    "\n",
    "def generate_hybrid_data():\n",
    "    # 1. Load the \"Real\" Base\n",
    "    company_names = load_base_companies('kaggle_companies.csv')\n",
    "    \n",
    "    # 2. Setup Companies Metadata\n",
    "    companies_meta = []\n",
    "    tiers = [\"Basic\", \"Pro\", \"Enterprise\"]\n",
    "    \n",
    "    for name in company_names:\n",
    "        comp_id = str(uuid.uuid4())[:8]\n",
    "        companies_meta.append({\n",
    "            \"company_id\": comp_id,\n",
    "            \"company_name\": name,\n",
    "            \"subscription_tier\": random.choice(tiers),\n",
    "            \"monthly_fee\": random.randint(5000, 75000),\n",
    "            \"is_at_risk\": random.random() < 0.2\n",
    "        })\n",
    "\n",
    "    # 3. Generate 5,000 Synthetic Logs\n",
    "    logs = []\n",
    "    features = [\"AI_Resume_Screen\", \"Bulk_Email\", \"Dashboard_View\", \"Job_Post_Creation\"]\n",
    "    end_date = datetime.now()\n",
    "    \n",
    "    for _ in range(5000):\n",
    "        comp = random.choice(companies_meta)\n",
    "        \n",
    "        # Churn Logic: 'At risk' companies have logs mostly older than 7 days\n",
    "        if comp[\"is_at_risk\"]:\n",
    "            days_ago = random.uniform(7, 30) \n",
    "        else:\n",
    "            days_ago = random.uniform(0, 30)\n",
    "            \n",
    "        timestamp = end_date - timedelta(days=days_ago)\n",
    "        \n",
    "        logs.append({\n",
    "            \"log_id\": str(uuid.uuid4()),\n",
    "            \"user_id\": f\"user_{random.randint(100, 999)}\",\n",
    "            \"company_id\": comp[\"company_id\"],\n",
    "            \"timestamp\": timestamp.isoformat(),\n",
    "            \"feature_used\": random.choice(features),\n",
    "            \"session_duration\": random.randint(5, 45)\n",
    "        })\n",
    "\n",
    "    # 4. Save Outputs\n",
    "    # Save Logs as JSON (Raw)\n",
    "    with open('users_activity.json', 'w') as f:\n",
    "        json.dump(logs, f, indent=4)\n",
    "    \n",
    "    # Save Metadata as CSV\n",
    "    meta_df = pd.DataFrame(companies_meta).drop(columns=['is_at_risk'])\n",
    "    meta_df.to_csv('account_meta.csv', index=False)\n",
    "    \n",
    "    print(\"Files 'users_activity.json' and 'account_meta.csv' are ready!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_hybrid_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0696ff-e486-4c3d-959e-5a863f68a758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading raw data...\n",
      "Connecting to MySQL database: saas_monitoring...\n",
      "Uploading 'account_health' table...\n",
      "Uploading 'raw_logs' table...\n",
      "\n",
      "ETL Complete! Open MySQL Workbench to query your data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import urllib.parse  # Required to handle the '@' in your password\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DB_USER = \"root\"\n",
    "DB_PASSWORD = \"aadithian@2003\" \n",
    "DB_HOST = \"localhost\"             # Changed from 'Data' to 'localhost'\n",
    "DB_PORT = \"3306\"\n",
    "DB_NAME = \"saas_monitoring\"\n",
    "\n",
    "def run_etl_mysql():\n",
    "    # 1. Load Data\n",
    "    print(\"Reading raw data...\")\n",
    "    try:\n",
    "        with open('users_activity.json', 'r') as f:\n",
    "            logs_data = json.load(f)\n",
    "        \n",
    "        df_logs = pd.DataFrame(logs_data)\n",
    "        df_meta = pd.read_csv('account_meta.csv')\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find data files. {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Convert timestamps to datetime objects\n",
    "    df_logs['timestamp'] = pd.to_datetime(df_logs['timestamp'])\n",
    "\n",
    "    # 3. Feature Engineering: Define \"AI Features\"\n",
    "    ai_features = ['AI_Resume_Screen']\n",
    "    \n",
    "    # Calculate Total Sessions and AI usage per company\n",
    "    stats = df_logs.groupby('company_id').agg(\n",
    "        total_sessions=('log_id', 'count'),\n",
    "        ai_usage=('feature_used', lambda x: x.isin(ai_features).sum())\n",
    "    ).reset_index()\n",
    "\n",
    "    # 4. Calculate Health Score (0-100 scale)\n",
    "    max_sessions = stats['total_sessions'].max() or 1\n",
    "    max_ai = stats['ai_usage'].max() or 1\n",
    "\n",
    "    stats['health_score'] = (\n",
    "        (stats['total_sessions'] / max_sessions * 40) + \n",
    "        (stats['ai_usage'] / max_ai * 60)\n",
    "    ).round(2)\n",
    "\n",
    "    # 5. Merge with Metadata\n",
    "    final_df = pd.merge(df_meta, stats, on='company_id', how='left')\n",
    "    final_df['health_score'] = final_df['health_score'].fillna(0)\n",
    "\n",
    "    # 6. Export to MySQL\n",
    "    try:\n",
    "        print(f\"Connecting to MySQL database: {DB_NAME}...\")\n",
    "        \n",
    "        # FIX: Percent-encode the password so the '@' doesn't break the connection string\n",
    "        safe_password = urllib.parse.quote_plus(DB_PASSWORD)\n",
    "        \n",
    "        # Build the connection URL using the safe password and localhost\n",
    "        connection_url = f\"mysql+mysqlconnector://{DB_USER}:{safe_password}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "        engine = create_engine(connection_url)\n",
    "        \n",
    "        # Save the main Health Table\n",
    "        print(\"Uploading 'account_health' table...\")\n",
    "        final_df.to_sql('account_health', engine, if_exists='replace', index=False)\n",
    "        \n",
    "        # Save the Raw Logs\n",
    "        print(\"Uploading 'raw_logs' table...\")\n",
    "        df_logs.to_sql('raw_logs', engine, if_exists='replace', index=False)\n",
    "        \n",
    "        print(\"\\nETL Complete! Open MySQL Workbench to query your data.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while connecting to MySQL: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_etl_mysql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c483a-4481-4d6b-bc21-e42a737abbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
